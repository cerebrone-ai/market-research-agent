This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-12-05T14:29:00.443Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.gitignore
main.py
src/config.py
src/models/research_models.py
src/services/document_service.py
src/services/llm_service.py
src/workflow/graph.py
src/workflow/nodes.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
storm/
.storm/
market-research/
.market-research/
env/
.env
.reports
reports/

*.env
.env
.env.local
.env.development
.env.production

__pycache__/
*.py[cod]
*$py.class

src/models/__pycache__/
services/__pycache__/
workflow/__pycache__/

================
File: main.py
================
import asyncio
from src.services.document_service import DocumentService
from src.workflow.graph import ResearchWorkflow
from dotenv import load_dotenv
import os

load_dotenv()

async def generate_market_research(topic: str):
    try:
        print(f"Starting market research on topic: {topic}")
        
        workflow = ResearchWorkflow()
        initial_state = {
            "topic": topic,
            "search_terms": None,
            "companies": [],
            "output_file": None
        }
        
        config = {"configurable": {"thread_id": "market-research-thread"}}
        final_state = await workflow.workflow.ainvoke(initial_state, config)
        
        print(f"\nFound {len(final_state['companies'])} providers/companies")
        
        filename = await DocumentService.save_to_excel(final_state["companies"])
        print(f"\nMarket research saved to: {filename}")
        return filename
        
    except Exception as e:
        print(f"An error occurred during market research for '{topic}': {str(e)}")
        raise e

async def main():
 
    #topic = "Generative AI, AI Agents Development, LangChain and CrewAI courses"
    topic = "House Cleaning Services in Charlotte, North Carolina"
    await generate_market_research(topic)

if __name__ == "__main__":
    asyncio.run(main())

================
File: src/config.py
================
import os

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')


# LLM Models
FAST_LLM_MODEL = "gpt-3.5-turbo-0125"
LONG_CONTEXT_MODEL = "gpt-4-turbo-preview"
EMBEDDINGS_MODEL = "text-embedding-3-small"

REPORTS_DIR = "reports"

================
File: src/models/research_models.py
================
from typing import List, Dict, Optional, Any, TypedDict
from pydantic import BaseModel, Field

class CompanyInfo(BaseModel):
    name: str
    products: List[str] = Field(default_factory=list)
    pricing: Dict[str, str] = Field(default_factory=dict)
    contact: Optional[str] = Field(default="Not available")
    website: Optional[str] = Field(default="Not available")
    rating: Optional[str] = Field(default="Not found")
    product_details: Dict[str, Dict] = Field(default_factory=lambda: {
        "features": {},
        "specifications": {},
        "availability": {}
    })
    review_analysis: Dict[str, Any] = Field(default_factory=lambda: {
        "total_reviews": "Not found",
        "average_rating": "Not found",
        "positive_points": [],
        "negative_points": [],
        "customer_sentiment": "Not analyzed"
    })
    market_details: Dict[str, Any] = Field(default_factory=lambda: {
        "market_share": "Not available",
        "target_segment": "Not specified",
        "key_competitors": []
    })

class SearchTerms(BaseModel):
    main_terms: List[str]
    related_terms: List[str]

class MarketResearchState(TypedDict):
    topic: str
    search_terms: Optional[SearchTerms]
    companies: List[CompanyInfo]
    output_file: Optional[str]

================
File: src/services/document_service.py
================
import pandas as pd
import os
from datetime import datetime
from ..models.research_models import CompanyInfo
from typing import List

class DocumentService:
    @staticmethod
    async def save_to_excel(companies: List[CompanyInfo]) -> str:
        """Save research data to Excel file."""
        try:
            data = []
            for company in companies:
                if not isinstance(company, CompanyInfo):
                    print(f"Warning: Skipping invalid company data: {company}")
                    continue
                    
                company_dict = company.model_dump()
                
                for product in company_dict['products']:
                    product_data = {
                        'Company Name': company_dict['name'],
                        'Product Name': product,
                        'Price': company_dict['pricing'].get(product, 'Not available'),
                        'Features': '\n'.join(company_dict['product_details']['features'].get(product, [])),
                        'Specifications': '\n'.join(company_dict['product_details']['specifications'].get(product, [])),
                        'Availability': company_dict['product_details']['availability'].get(product, 'Not specified'),
                        'Company Rating': company_dict['rating'],
                        'Total Reviews': company_dict['review_analysis']['total_reviews'],
                        'Average Rating': company_dict['review_analysis']['average_rating'],
                        'Positive Points': '\n'.join(company_dict['review_analysis']['positive_points']),
                        'Negative Points': '\n'.join(company_dict['review_analysis']['negative_points']),
                        'Customer Sentiment': company_dict['review_analysis']['customer_sentiment'],
                        'Market Share': company_dict['market_details']['market_share'],
                        'Target Segment': company_dict['market_details']['target_segment'],
                        'Key Competitors': '\n'.join(company_dict['market_details']['key_competitors']),
                        'Website': company_dict['website'],
                        'Contact': company_dict['contact']
                    }
                    data.append(product_data)
            
            if not data:
                print("Warning: No valid data to export")
                return "reports/no_data.txt"
                
            df = pd.DataFrame(data)
            
            os.makedirs('reports', exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"reports/market_research_{timestamp}.xlsx"
            
            with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='Market Research')
                
                workbook = writer.book
                worksheet = writer.sheets['Market Research']
                
                header_format = workbook.add_format({
                    'bold': True,
                    'bg_color': '#4F81BD',
                    'font_color': 'white',
                    'border': 1
                })
                
                for col_num, value in enumerate(df.columns.values):
                    worksheet.write(0, col_num, value, header_format)
                
                for idx, col in enumerate(df.columns):
                    max_length = max(
                        df[col].astype(str).apply(len).max(),
                        len(col)
                    ) + 2
                    worksheet.set_column(idx, idx, min(max_length, 50))
                
                worksheet.autofilter(0, 0, len(df), len(df.columns) - 1)
            
            print(f"\nSuccessfully exported {len(data)} items to Excel")
            return filename
            
        except Exception as e:
            print(f"Error saving to Excel: {str(e)}")
            error_file = "reports/export_error.txt"
            os.makedirs('reports', exist_ok=True)
            with open(error_file, 'w') as f:
                f.write(f"Error exporting data: {str(e)}")
            return error_file

================
File: src/services/llm_service.py
================
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.retrievers import WikipediaRetriever
from langchain_community.tools.tavily_search import TavilySearchResults
from ..config import FAST_LLM_MODEL, LONG_CONTEXT_MODEL, EMBEDDINGS_MODEL

class LLMService:
    def __init__(self):
        self.fast_llm = ChatOpenAI(model=FAST_LLM_MODEL)
        self.long_context_llm = ChatOpenAI(model=LONG_CONTEXT_MODEL)
        self.embeddings = OpenAIEmbeddings(model=EMBEDDINGS_MODEL)
        self.wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=3)
        self.tavily_search = TavilySearchResults(max_results=3)

================
File: src/workflow/graph.py
================
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from ..models.research_models import MarketResearchState
from ..services.document_service import DocumentService
from .nodes import WorkflowNodes

class ResearchWorkflow:
    def __init__(self):
        self.nodes = WorkflowNodes()
        self.document_service = DocumentService()
        self.workflow = self._create_workflow()

    async def export_data(self, state):
        """Export data to Excel and return updated state."""
        filename = await self.document_service.save_to_excel(state["companies"])
        return {**state, "output_file": filename}

    def _create_workflow(self):
        workflow = StateGraph(MarketResearchState)
        
        workflow.add_node("generate_search_terms", self.nodes.generate_search_terms)
        workflow.add_node("gather_company_data", self.nodes.gather_company_data)
        workflow.add_node("export_report", self.export_data)

        workflow.add_edge(START, "generate_search_terms")
        workflow.add_edge("generate_search_terms", "gather_company_data")
        workflow.add_edge("gather_company_data", "export_report")
        workflow.add_edge("export_report", END)

        return workflow.compile(checkpointer=MemorySaver())

================
File: src/workflow/nodes.py
================
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from ..services.llm_service import LLMService
from ..models.research_models import SearchTerms, CompanyInfo
from typing import List
from pydantic import BaseModel
import json
import asyncio

class CompaniesResponse(BaseModel):
    companies: List[CompanyInfo]

class WorkflowNodes:
    def __init__(self):
        self.llm_service = LLMService()

    async def generate_search_terms(self, state):
        """Generate focused search terms based on the research topic."""
        search_terms_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a research specialist. Analyze the given topic and generate relevant search terms.
            
            For any topic (products, courses, services, companies, etc.), create three categories of search terms:
            1. Primary Terms (4-5 terms):
               - Exact names/titles
               - Main keywords
               - Specific identifiers
               
            2. Provider/Platform Terms (4-5 terms):
               - Companies/Organizations offering the item
               - Platforms/Websites
               - Distribution channels
               
            3. Review/Analysis Terms (3-4 terms):
               - Reviews and ratings
               - Comparisons
               - User experiences/feedback"""),
            ("user", "Create focused search terms for researching: {topic}")
        ])
        
        generate_terms = search_terms_prompt | self.llm_service.fast_llm.with_structured_output(SearchTerms)
        search_terms = await generate_terms.ainvoke({"topic": state["topic"]})
        return {**state, "search_terms": search_terms}

    async def gather_company_data(self, state):
        """Gather comprehensive research data based on the topic."""
        search_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a research specialist. Extract structured information from search results into this exact format.
            You MUST provide actual values for each field - do not return empty or placeholder values.
            If information is truly not available, use 'Not found' or 'Not available'.

            {{
                "companies": [
                    {{
                        "name": "REQUIRED: Actual company/provider name",
                        "products": ["REQUIRED: At least one actual product/course name"],
                        "pricing": {{
                            "REQUIRED: Product/Course Name": "REQUIRED: Actual price or price range"
                        }},
                        "website": "REQUIRED: Actual website URL or 'Not found'",
                        "contact": "Contact information or 'Not found'",
                        "rating": "Numerical rating or 'Not found'",
                        "product_details": {{
                            "features": {{
                                "REQUIRED: Product/Course Name": ["REQUIRED: At least 2-3 actual features"]
                            }},
                            "specifications": {{
                                "REQUIRED: Product/Course Name": ["At least 2 specifications"]
                            }},
                            "availability": {{
                                "REQUIRED: Product/Course Name": "Available/Not Available"
                            }}
                        }},
                        "review_analysis": {{
                            "total_reviews": "Number or 'Not found'",
                            "average_rating": "Numerical or 'Not found'",
                            "positive_points": ["REQUIRED: At least 2 actual positive points"],
                            "negative_points": ["At least 2 negative points or 'None reported'"],
                            "customer_sentiment": "REQUIRED: Actual sentiment description"
                        }},
                        "market_details": {{
                            "market_share": "Percentage/description or 'Not found'",
                            "target_segment": "REQUIRED: Actual target audience description",
                            "key_competitors": ["REQUIRED: At least 2 actual competitors"]
                        }}
                    }}
                ]
            }}"""),
            ("user", """Research topic: {topic}
            Extract detailed information from these search results: {results}
            
            Important instructions:
            1. You MUST provide actual, specific information for each required field
            2. Do not return empty arrays or placeholder text
            3. Include real pricing for each product/course
            4. If information is truly not available, use 'Not found' or 'Not available'
            5. Ensure company names are real and specific
            6. Each company entry must have at least one product/course with details""")
        ])

        process_results = search_prompt | self.llm_service.long_context_llm.with_structured_output(CompaniesResponse)

        async def perform_search(term, max_retries=3):
            for attempt in range(max_retries):
                try:
                    results = await self.llm_service.tavily_search.ainvoke(term)
                    print(f"Search results for '{term}': {results}")
                    await asyncio.sleep(5)
                    return results
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 10
                        print(f"Rate limit hit, waiting {wait_time} seconds before retry...")
                        await asyncio.sleep(wait_time)
                    else:
                        print(f"Search error for '{term}': {str(e)}")
                        return []
            return []

        search_queries = []
        if "cleaning" in state["topic"].lower():
            for main_term in state["search_terms"].main_terms[:2]:
                search_queries.extend([
                    f"{main_term} companies prices reviews",
                    f"{main_term} top rated services"
                ])
        else:
            for main_term in state["search_terms"].main_terms:
                if "course" in state["topic"].lower() or "training" in state["topic"].lower():
                    search_queries.extend([
                        f"{main_term} course curriculum price",
                        f"{main_term} training reviews ratings",
                        f"{main_term} certification learning platform"
                    ])
                elif "product" in state["topic"].lower():
                    search_queries.extend([
                        f"{main_term} product specifications features",
                        f"{main_term} price comparison reviews",
                        f"{main_term} availability retailers"
                    ])
                else:  
                    search_queries.extend([
                        f"{main_term} provider details pricing",
                        f"{main_term} reviews ratings feedback",
                        f"{main_term} market analysis comparison"
                    ])

        companies = []
        batch_size = 2
        for i in range(0, len(search_queries), batch_size):
            batch = search_queries[i:i + batch_size]
            batch_results = await asyncio.gather(
                *(perform_search(query) for query in batch)
            )
            
            for results in batch_results:
                if results:
                    try:
                        parsed_data = await process_results.ainvoke({
                            "topic": state["topic"],
                            "results": results
                        })
                        companies.extend(parsed_data.companies)
                    except Exception as e:
                        print(f"Parsing error: {str(e)}")
                        continue
            
            await asyncio.sleep(10)

        unique_companies = {company.name: company for company in companies}.values()
        
        print(f"\nTotal unique providers/platforms found: {len(unique_companies)}")
        
        print("\nRelevant results found:")
        for company in unique_companies:
            print(f"- {company.name}")
            if company.products:
                print(f"  Products: {', '.join(company.products)}")
            if company.rating:
                print(f"  Rating: {company.rating}")
            if company.pricing:
                for product, price in company.pricing.items():
                    print(f"  Price for {product}: {price}")
        
        return {**state, "companies": list(unique_companies)}
